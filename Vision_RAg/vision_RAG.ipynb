{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyzdP+SFkX0tsQMHYGRJ6y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/notzabir/EBL_IT_INTERNSHIP_2025/blob/main/Vision_RAg/vision_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1af6342a"
      },
      "source": [
        "# Task\n",
        "Build a vision RAG pipeline to process and analyze images from a PDF using the \"Salesforce/blip-image-captioning-base\" model. The pipeline should extract all images, allow selection by number of images or page number, and retrieve and describe relevant images based on questions from the PDF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7b6281f"
      },
      "source": [
        "## Setup\n",
        "\n",
        "### Subtask:\n",
        "Install necessary libraries for PDF processing, image handling, and the BLIP model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6d6d9e6"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the required libraries for PDF processing, image handling, and the BLIP model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5cef640",
        "outputId": "431c80de-3a1d-414f-e921-6efd67be1800"
      },
      "source": [
        "%pip install PyMuPDF Pillow torch transformers faiss-cpu"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.26.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf31c25b"
      },
      "source": [
        "## Pdf image extraction\n",
        "\n",
        "### Subtask:\n",
        "Extract images from the specified PDF document.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feb0d0d5"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the `fitz` library and define a function to extract images from a PDF, storing the image data, page number, and image index.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4441875b",
        "outputId": "a38e9633-27af-400a-ea11-7ccb0c34ad7b"
      },
      "source": [
        "import fitz\n",
        "import io\n",
        "from PIL import Image\n",
        "import os # Import the os module\n",
        "\n",
        "def extract_images_from_pdf(pdf_path, output_folder=\"extracted_images\"):\n",
        "    \"\"\"Extracts images from a PDF document and saves them to a folder.\"\"\"\n",
        "    extracted_images = []\n",
        "    doc = fitz.open(pdf_path)\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for page_number in range(len(doc)):\n",
        "        page = doc.load_page(page_number)\n",
        "        images = page.get_images(full=True)\n",
        "\n",
        "        for img_index, img in enumerate(images):\n",
        "            xref = img[0]\n",
        "            base_image = doc.extract_image(xref)\n",
        "            image_bytes = base_image[\"image\"]\n",
        "            image_ext = base_image[\"ext\"]\n",
        "\n",
        "            try:\n",
        "                # Verify if it's a valid image\n",
        "                img_pil = Image.open(io.BytesIO(image_bytes))\n",
        "\n",
        "                # Define the output path for the image\n",
        "                image_filename = f\"page_{page_number}_img_{img_index}.{image_ext}\"\n",
        "                image_path = os.path.join(output_folder, image_filename)\n",
        "\n",
        "                # Save the image to the output folder\n",
        "                img_pil.save(image_path)\n",
        "\n",
        "                extracted_images.append({\n",
        "                    'page_number': page_number,\n",
        "                    'image_index': img_index,\n",
        "                    'image_path': image_path, # Store the image path instead of data\n",
        "                    'caption': None # Initialize caption as None\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Could not process or save image on page {page_number}, index {img_index}: {e}\")\n",
        "\n",
        "    doc.close()\n",
        "    return extracted_images\n",
        "\n",
        "# Replace with the actual path to your PDF file\n",
        "pdf_path = \"ebl_annual_report_2024.pdf\"\n",
        "extracted_images_list = extract_images_from_pdf(pdf_path)\n",
        "\n",
        "# For demonstration, let's assume we have a dummy PDF or skip execution if no PDF is provided\n",
        "print(f\"Extracted {len(extracted_images_list)} images.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 137 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70ff4f28"
      },
      "source": [
        "## Image captioning\n",
        "\n",
        "### Subtask:\n",
        "Use the \"Salesforce/blip-image-captioning-base\" model to generate captions for the extracted images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f6aa597"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary classes from the transformers library, load the model and processor, and iterate through the extracted images to generate captions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "33bdafc0",
        "outputId": "ce95e563-d2eb-4781-9592-ebfbc6098c2a"
      },
      "source": [
        "from transformers import BlipForConditionalGeneration, BlipProcessor\n",
        "import torch\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Load the pre-trained BLIP model and processor\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "# Assume extracted_images_list is available from the previous step\n",
        "# If not, create a dummy list for demonstration purposes\n",
        "if 'extracted_images_list' not in locals() or not extracted_images_list:\n",
        "    print(\"extracted_images_list is not available or empty. Creating dummy data.\")\n",
        "    # Create a dummy image file\n",
        "    dummy_image = Image.new('RGB', (60, 30), color = 'red')\n",
        "    dummy_folder = \"dummy_images\"\n",
        "    if not os.path.exists(dummy_folder):\n",
        "        os.makedirs(dummy_folder)\n",
        "    dummy_image_path_1 = os.path.join(dummy_folder, \"dummy_img_1.png\")\n",
        "    dummy_image.save(dummy_image_path_1)\n",
        "    dummy_image_path_2 = os.path.join(dummy_folder, \"dummy_img_2.png\")\n",
        "    dummy_image.save(dummy_image_path_2)\n",
        "\n",
        "\n",
        "    extracted_images_list = [\n",
        "        {'page_number': 0, 'image_index': 0, 'image_path': dummy_image_path_1, 'caption': None},\n",
        "        {'page_number': 1, 'image_index': 0, 'image_path': dummy_image_path_2, 'caption': None}\n",
        "    ]\n",
        "\n",
        "\n",
        "# Iterate through the extracted images and generate captions\n",
        "for image_info in extracted_images_list:\n",
        "    try:\n",
        "        # Open the image from the saved file path\n",
        "        raw_image = Image.open(image_info['image_path']).convert('RGB')\n",
        "\n",
        "        # Check if the image was opened successfully\n",
        "        if raw_image is None:\n",
        "            print(f\"Could not open image file: {image_info['image_path']}\")\n",
        "            image_info['caption'] = \"Error opening image file\"\n",
        "            continue\n",
        "\n",
        "        # Preprocess the image\n",
        "        inputs = processor(raw_image, return_tensors=\"pt\")\n",
        "\n",
        "        # Generate a caption\n",
        "        out = model.generate(**inputs)\n",
        "\n",
        "        # Decode the generated caption\n",
        "        caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "        # Add the caption to the dictionary\n",
        "        image_info['caption'] = caption\n",
        "        print(f\"Generated caption for image on page {image_info['page_number']}, index {image_info['image_index']}: {caption}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Could not generate caption for image on page {image_info['page_number']}, index {image_info['image_index']}: {e}\")\n",
        "        image_info['caption'] = \"Error generating caption\" # Add an error placeholder\n",
        "\n",
        "# Store the updated list (extracted_images_list is updated in place)\n",
        "# You can optionally create a new variable if you prefer\n",
        "captioned_images_list = extracted_images_list\n",
        "\n",
        "# Display the first few items in the updated list to verify\n",
        "print(\"\\nUpdated extracted_images_list with captions:\")\n",
        "display(captioned_images_list[:3])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated caption for image on page 0, index 0: a white background with a blue and yellow text that reads reflect\n",
            "Generated caption for image on page 2, index 0: a white and black photo of a lake\n",
            "Generated caption for image on page 2, index 1: a flock of birds flying in the sky\n",
            "Generated caption for image on page 2, index 2: the logo for the university of north carolina\n",
            "Generated caption for image on page 2, index 3: the logo for the university of north carolina\n",
            "Generated caption for image on page 2, index 4: the logo for the new youtube app\n",
            "Generated caption for image on page 5, index 0: a foggy lake\n",
            "Generated caption for image on page 5, index 1: a square frame with a white background\n",
            "Generated caption for image on page 6, index 0: a lone tree in the fog on a lake\n",
            "Generated caption for image on page 7, index 0: a body of water\n",
            "Generated caption for image on page 8, index 0: a large body of water with mountains in the background\n",
            "Generated caption for image on page 9, index 0: a mountain with trees and fog\n",
            "Generated caption for image on page 10, index 0: a blue car with a white background\n",
            "Generated caption for image on page 10, index 1: a dark green color with a white background\n",
            "Generated caption for image on page 10, index 2: the sky is clear\n",
            "Generated caption for image on page 10, index 3: a blue square with a white border\n",
            "Generated caption for image on page 10, index 4: a green and black color\n",
            "Generated caption for image on page 10, index 5: a dark green color with a black stripe\n",
            "Generated caption for image on page 12, index 0: the trophy trophy\n",
            "Generated caption for image on page 12, index 1: the cover of the book, the art of the golden flower\n",
            "Generated caption for image on page 12, index 2: a robot with a blue light on it ' s head\n",
            "Generated caption for image on page 12, index 3: a trophy with a green shirt on it\n",
            "Generated caption for image on page 12, index 4: the award for best new product\n",
            "Generated caption for image on page 12, index 5: a white and blue sign with a red heart\n",
            "Generated caption for image on page 12, index 6: a group of three candles with a black background\n",
            "Generated caption for image on page 12, index 7: a computer screen with a blue and white pattern\n",
            "Generated caption for image on page 12, index 8: the red and yellow logo on the back of a white and red poster\n",
            "Generated caption for image on page 12, index 9: thermo®™™™™™™™™™™™™™™™™\n",
            "Generated caption for image on page 12, index 10: a gold wave pattern on a black background\n",
            "Generated caption for image on page 12, index 11: a black shield with gold accents\n",
            "Generated caption for image on page 12, index 12: a black background with a bunch of flowers\n",
            "Generated caption for image on page 12, index 13: a blury background with a blury effect\n",
            "Generated caption for image on page 12, index 14: a black and red gradient background\n",
            "Generated caption for image on page 12, index 15: a black and white photo of a cross\n",
            "Generated caption for image on page 12, index 16: a white packet with a red and yellow label\n",
            "Generated caption for image on page 12, index 17: a white plate with a green and yellow logo\n",
            "Generated caption for image on page 12, index 18: a brown square with a white border\n",
            "Generated caption for image on page 12, index 19: a yellow square with a white background\n",
            "Generated caption for image on page 12, index 20: a brown square with a white border\n",
            "Generated caption for image on page 12, index 21: the logo for the band ' s new album\n",
            "Generated caption for image on page 12, index 22: a blue plastic bag with a white lid\n",
            "Generated caption for image on page 12, index 23: the black shield with the flag of the republic of the republic\n",
            "Generated caption for image on page 12, index 24: the wireless microphone system\n",
            "Generated caption for image on page 12, index 25: a white disc with a black base\n",
            "Generated caption for image on page 12, index 26: a white disc with a red dot on the disc\n",
            "Generated caption for image on page 12, index 27: a certificate for a business\n",
            "Generated caption for image on page 12, index 28: the trophy trophy\n",
            "Generated caption for image on page 13, index 0: a yellow flag flying in the air\n",
            "Generated caption for image on page 14, index 0: a picture of the word over a foggy sky\n",
            "Generated caption for image on page 19, index 0: the logo for the company\n",
            "Generated caption for image on page 21, index 0: the logo for the new google app\n",
            "Generated caption for image on page 23, index 0: a circle with a reflection in the water\n",
            "Generated caption for image on page 24, index 0: a yellow and blue painting with a black background\n",
            "Generated caption for image on page 24, index 1: the logo for the bangladesh bank\n",
            "Generated caption for image on page 24, index 2: a pixel style star\n",
            "Generated caption for image on page 24, index 3: a pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel\n",
            "Generated caption for image on page 24, index 4: a pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel pixel\n",
            "Generated caption for image on page 24, index 5: aco success stories eil\n",
            "Generated caption for image on page 24, index 6: the logo for the new project, the project\n",
            "Generated caption for image on page 24, index 7: eastern bank plc logo\n",
            "Generated caption for image on page 25, index 0: a man in a suit and tie\n",
            "Generated caption for image on page 25, index 1: a man in a suit and tie with his hands folded\n",
            "Generated caption for image on page 26, index 0: a man in a suit and glasses\n",
            "Generated caption for image on page 26, index 1: a woman in a black sari sari\n",
            "Generated caption for image on page 27, index 0: an old woman in a purple sari\n",
            "Generated caption for image on page 27, index 1: a man in a suit and glasses\n",
            "Generated caption for image on page 28, index 0: a man in a suit and tie with a white shirt\n",
            "Generated caption for image on page 28, index 1: a woman in a white shirt and black pants\n",
            "Generated caption for image on page 29, index 0: a man in a blue suit and pink tie\n",
            "Generated caption for image on page 29, index 1: a woman in a black dress\n",
            "Generated caption for image on page 30, index 0: a man in a suit and tie\n",
            "Generated caption for image on page 30, index 1: a man in a suit and tie with glasses\n",
            "Generated caption for image on page 31, index 0: a man in a suit and tie standing with his hands folded\n",
            "Generated caption for image on page 32, index 0: three men in traditional clothing standing together\n",
            "Generated caption for image on page 33, index 0: a group of men in suits and ties standing in front of a concrete wall\n",
            "Generated caption for image on page 34, index 0: a group of men in suits and ties standing in front of a concrete wall\n",
            "Generated caption for image on page 35, index 0: a graph with the number of people in each country\n",
            "Generated caption for image on page 35, index 1: a graph with the number of people in each country\n",
            "Generated caption for image on page 37, index 0: a graph with the number of the data\n",
            "Generated caption for image on page 37, index 1: a graph with the number of the data displayed\n",
            "Generated caption for image on page 38, index 0: a graph with the number of people in each country\n",
            "Generated caption for image on page 39, index 0: a graph with the number of the data\n",
            "Generated caption for image on page 39, index 1: a graph with the number of the data\n",
            "Generated caption for image on page 39, index 2: a graph with the number of people in each country\n",
            "Generated caption for image on page 41, index 0: a blue square with a white border\n",
            "Generated caption for image on page 41, index 1: a blue square icon with a white background\n",
            "Generated caption for image on page 41, index 2: a blue square icon with a white background\n",
            "Generated caption for image on page 41, index 3: a blue square with a white border\n",
            "Generated caption for image on page 41, index 4: a blue square with a white border\n",
            "Generated caption for image on page 41, index 5: a blue square with a white border\n",
            "Generated caption for image on page 42, index 0: a blue square with a white border\n",
            "Generated caption for image on page 42, index 1: a blue square icon\n",
            "Generated caption for image on page 42, index 2: a blue square with a white border\n",
            "Generated caption for image on page 42, index 3: a blue square icon with a white background\n",
            "Generated caption for image on page 42, index 4: a blue square with a white border\n",
            "Generated caption for image on page 42, index 5: a blue square with a white border\n",
            "Generated caption for image on page 42, index 6: a square icon with a blue background\n",
            "Generated caption for image on page 42, index 7: a blue square with a white border\n",
            "Generated caption for image on page 43, index 0: a square with a blue background\n",
            "Generated caption for image on page 43, index 1: a blue square icon with a white background\n",
            "Generated caption for image on page 43, index 2: a blue square icon with a white background\n",
            "Generated caption for image on page 43, index 3: a blue square with a white border\n",
            "Generated caption for image on page 43, index 4: a blue square with a white border\n",
            "Generated caption for image on page 43, index 5: a blue square with a white border\n",
            "Generated caption for image on page 43, index 6: a blue square icon\n",
            "Generated caption for image on page 43, index 7: a blue square with a white border\n",
            "Generated caption for image on page 43, index 8: a blue square icon\n",
            "Generated caption for image on page 43, index 9: a blue square icon\n",
            "Generated caption for image on page 43, index 10: a blue square with a white border\n",
            "Generated caption for image on page 43, index 11: a blue square with a white border\n",
            "Generated caption for image on page 44, index 0: a blue square with a white border\n",
            "Generated caption for image on page 44, index 1: a blue square with a white border\n",
            "Generated caption for image on page 44, index 2: a blue square with a white border\n",
            "Generated caption for image on page 44, index 3: a blue square with a white border\n",
            "Generated caption for image on page 44, index 4: a blue square with a white border\n",
            "Generated caption for image on page 44, index 5: a blue square with a white border\n",
            "Generated caption for image on page 44, index 6: a blue square icon\n",
            "Generated caption for image on page 44, index 7: a blue square icon\n",
            "Generated caption for image on page 44, index 8: a blue square with a white border\n",
            "Generated caption for image on page 45, index 0: a black smoke cloud in the dark\n",
            "Generated caption for image on page 46, index 0: a black smoke cloud in the dark\n",
            "Generated caption for image on page 47, index 0: a group of people holding up signs\n",
            "Generated caption for image on page 47, index 1: a group of men standing around a table\n",
            "Generated caption for image on page 47, index 2: the group of people standing in front of a table\n",
            "Generated caption for image on page 47, index 3: a group of men standing around a long table\n",
            "Generated caption for image on page 47, index 4: a group of people standing in a room\n",
            "Generated caption for image on page 47, index 5: a group of people standing in front of a large screen\n",
            "Generated caption for image on page 47, index 6: a group of people standing on a stage\n",
            "Generated caption for image on page 47, index 7: the men are standing on the stage\n",
            "Generated caption for image on page 48, index 0: a group of people standing in a room\n",
            "Generated caption for image on page 48, index 1: a group of people standing around a large balloon\n",
            "Generated caption for image on page 48, index 2: the winners of the 2018 world water prize\n",
            "Generated caption for image on page 48, index 3: a group of people holding up signs\n",
            "Generated caption for image on page 48, index 4: a group of people standing on a stage\n",
            "Generated caption for image on page 48, index 5: a man in a suit\n",
            "Generated caption for image on page 48, index 6: the winners of the 2019 global awards\n",
            "Generated caption for image on page 48, index 7: the winners of the 2018 africa tourism awards\n",
            "\n",
            "Updated extracted_images_list with captions:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'page_number': 0,\n",
              "  'image_index': 0,\n",
              "  'image_path': 'extracted_images/page_0_img_0.jpeg',\n",
              "  'caption': 'a white background with a blue and yellow text that reads reflect'},\n",
              " {'page_number': 2,\n",
              "  'image_index': 0,\n",
              "  'image_path': 'extracted_images/page_2_img_0.jpeg',\n",
              "  'caption': 'a white and black photo of a lake'},\n",
              " {'page_number': 2,\n",
              "  'image_index': 1,\n",
              "  'image_path': 'extracted_images/page_2_img_1.jpeg',\n",
              "  'caption': 'a flock of birds flying in the sky'}]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57f797f6"
      },
      "source": [
        "## Indexing\n",
        "\n",
        "### Subtask:\n",
        "Create an index (e.g., using a vector database or similar structure) to store the image captions and their corresponding image/page information.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38425fbc"
      },
      "source": [
        "**Reasoning**:\n",
        "Initialize the FAISS index and a sentence transformer model, then iterate through the captioned images to generate embeddings and add them to the index while storing the image information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "375535e9",
        "outputId": "21e4a30f-62be-4578-ceab-fc617491546e"
      },
      "source": [
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Initialize a sentence transformer model\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Assume captioned_images_list is available from the previous step\n",
        "# If not, create a dummy list for demonstration purposes\n",
        "if 'captioned_images_list' not in locals() or not captioned_images_list:\n",
        "    print(\"captioned_images_list is not available or empty. Creating dummy data.\")\n",
        "    captioned_images_list = [\n",
        "        {'page_number': 0, 'image_index': 0, 'caption': 'a red square'},\n",
        "        {'page_number': 1, 'image_index': 0, 'caption': 'a blue circle'},\n",
        "        {'page_number': 2, 'image_index': 0, 'caption': 'a green triangle'}\n",
        "    ]\n",
        "\n",
        "# Get the dimensionality of the embeddings\n",
        "embedding_dim = embedding_model.get_sentence_embedding_dimension()\n",
        "\n",
        "# Initialize a FAISS index\n",
        "index = faiss.IndexFlatL2(embedding_dim)\n",
        "\n",
        "# List to store the mapping from index ID to image information\n",
        "index_to_image_info = []\n",
        "\n",
        "# Iterate through the captioned images and add embeddings to the index\n",
        "for i, image_info in enumerate(captioned_images_list):\n",
        "    caption = image_info['caption']\n",
        "    if caption and caption != \"Error generating caption\": # Only process if a valid caption exists\n",
        "        # Generate embedding for the caption\n",
        "        embedding = embedding_model.encode(caption)\n",
        "        # Reshape the embedding to be a 2D numpy array\n",
        "        embedding = np.array([embedding])\n",
        "\n",
        "        # Add the embedding to the FAISS index\n",
        "        index.add(embedding)\n",
        "\n",
        "        # Store the image information, mapping the index ID to the info\n",
        "        index_to_image_info.append({\n",
        "            'page_number': image_info['page_number'],\n",
        "            'image_index': image_info['image_index']\n",
        "        })\n",
        "    else:\n",
        "        print(f\"Skipping image on page {image_info.get('page_number')}, index {image_info.get('image_index')} due to missing or error caption.\")\n",
        "\n",
        "\n",
        "# Verify the number of items in the index\n",
        "print(f\"Number of items in FAISS index: {index.ntotal}\")\n",
        "print(f\"Number of items in index_to_image_info list: {len(index_to_image_info)}\")\n",
        "\n",
        "# Check if the counts match\n",
        "if index.ntotal == len(index_to_image_info):\n",
        "    print(\"Index count matches the number of successfully captioned images.\")\n",
        "else:\n",
        "    print(\"Warning: Index count does not match the number of successfully captioned images.\")\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of items in FAISS index: 137\n",
            "Number of items in index_to_image_info list: 137\n",
            "Index count matches the number of successfully captioned images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5794a92"
      },
      "source": [
        "## Retrieval\n",
        "\n",
        "### Subtask:\n",
        "Implement a mechanism to retrieve relevant image captions based on user queries (e.g., questions, page numbers, or number of images).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "872adac8"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the function to retrieve images based on user queries, handling text questions, page numbers, and specific numbers of images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "1a443c1a",
        "outputId": "a6338a59-fd71-4c31-8d4b-79f6e1d93cce"
      },
      "source": [
        "import re # Import regex for checking if the query is a number\n",
        "\n",
        "def retrieve_images(query, captioned_images_list, index, index_to_image_info, embedding_model, N=5):\n",
        "    \"\"\"\n",
        "    Retrieves relevant image information based on a user query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The user query (text question, page number, or number of images).\n",
        "        captioned_images_list (list): List of dictionaries with image info and captions.\n",
        "        index (faiss.Index): The FAISS index containing caption embeddings.\n",
        "        index_to_image_info (list): List mapping index ID to image info.\n",
        "        embedding_model: The sentence transformer model for generating query embeddings.\n",
        "        N (int): The number of top results to retrieve for text queries.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries containing the retrieved image information.\n",
        "    \"\"\"\n",
        "    retrieved_images = []\n",
        "\n",
        "    # Check if the query is a page number (numeric)\n",
        "    if re.match(r'^\\d+$', query):\n",
        "        page_number = int(query)\n",
        "        print(f\"Query recognized as page number: {page_number}\")\n",
        "        for image_info in captioned_images_list:\n",
        "            if image_info.get('page_number') == page_number:\n",
        "                retrieved_images.append(image_info)\n",
        "        print(f\"Found {len(retrieved_images)} images on page {page_number}.\")\n",
        "\n",
        "    # Check if the query is a request for a specific number of images (e.g., \"first 3 images\")\n",
        "    elif re.match(r'^(first|top)\\s+(\\d+)\\s+images$', query.lower()):\n",
        "        match = re.match(r'^(first|top)\\s+(\\d+)\\s+images$', query.lower())\n",
        "        num_images = int(match.group(2))\n",
        "        print(f\"Query recognized as request for first {num_images} images.\")\n",
        "        retrieved_images = captioned_images_list[:num_images]\n",
        "        print(f\"Retrieving the first {len(retrieved_images)} images.\")\n",
        "\n",
        "    # Otherwise, treat the query as a text question\n",
        "    else:\n",
        "        print(f\"Query recognized as text question: \\\"{query}\\\"\")\n",
        "        try:\n",
        "            # Generate embedding for the query\n",
        "            query_embedding = embedding_model.encode(query)\n",
        "            query_embedding = np.array([query_embedding]) # Reshape for FAISS\n",
        "\n",
        "            # Search the FAISS index\n",
        "            # Ensure N does not exceed the number of indexed items\n",
        "            k = min(N, index.ntotal)\n",
        "            if k > 0:\n",
        "                distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "                # Retrieve the corresponding image information\n",
        "                for i in indices[0]:\n",
        "                    # Check if the index is valid\n",
        "                    if i < len(index_to_image_info):\n",
        "                        img_info = index_to_image_info[i]\n",
        "                        # Find the full image info from captioned_images_list using page_number and image_index\n",
        "                        for full_img_info in captioned_images_list:\n",
        "                            if full_img_info.get('page_number') == img_info['page_number'] and \\\n",
        "                               full_img_info.get('image_index') == img_info['image_index']:\n",
        "                                retrieved_images.append(full_img_info)\n",
        "                                break # Found the image, move to the next index\n",
        "                    else:\n",
        "                        print(f\"Warning: Invalid index {i} retrieved from FAISS.\")\n",
        "\n",
        "                print(f\"Retrieved {len(retrieved_images)} images based on text query.\")\n",
        "            else:\n",
        "                 print(\"FAISS index is empty. Cannot perform text search.\")\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during text query retrieval: {e}\")\n",
        "\n",
        "\n",
        "    return retrieved_images\n",
        "\n",
        "# Example Usage (Assuming captioned_images_list, index, index_to_image_info, embedding_model are defined)\n",
        "# Example 1: Text query\n",
        "query = \"images about trophy\"\n",
        "retrieved_results = retrieve_images(query, captioned_images_list, index, index_to_image_info, embedding_model, N=3)\n",
        "print(\"\\nResults for text query:\")\n",
        "display(retrieved_results)\n",
        "\n",
        "# Example 2: Page number query (assuming page 0 has images)\n",
        "query = \"0\"\n",
        "retrieved_results = retrieve_images(query, captioned_images_list, index, index_to_image_info, embedding_model)\n",
        "print(\"\\nResults for page number query:\")\n",
        "display(retrieved_results)\n",
        "\n",
        "# Example 3: Number of images query\n",
        "# query = \"first 2 images\"\n",
        "# retrieved_results = retrieve_images(query, captioned_images_list, index, index_to_image_info, embedding_model)\n",
        "# print(\"\\nResults for number of images query:\")\n",
        "# display(retrieved_results)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query recognized as text question: \"images about trophy\"\n",
            "Retrieved 3 images based on text query.\n",
            "\n",
            "Results for text query:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'page_number': 12,\n",
              "  'image_index': 0,\n",
              "  'image_path': 'extracted_images/page_12_img_0.png',\n",
              "  'caption': 'the trophy trophy'},\n",
              " {'page_number': 12,\n",
              "  'image_index': 28,\n",
              "  'image_path': 'extracted_images/page_12_img_28.png',\n",
              "  'caption': 'the trophy trophy'},\n",
              " {'page_number': 12,\n",
              "  'image_index': 3,\n",
              "  'image_path': 'extracted_images/page_12_img_3.png',\n",
              "  'caption': 'a trophy with a green shirt on it'}]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query recognized as page number: 0\n",
            "Found 1 images on page 0.\n",
            "\n",
            "Results for page number query:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'page_number': 0,\n",
              "  'image_index': 0,\n",
              "  'image_path': 'extracted_images/page_0_img_0.jpeg',\n",
              "  'caption': 'a white background with a blue and yellow text that reads reflect'}]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "586c0906"
      },
      "source": [
        "## Response generation\n",
        "\n",
        "### Subtask:\n",
        "Based on the retrieved captions, provide the user with the relevant image descriptions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aaf880d"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the `generate_response` function to format the retrieved image information and then call it with an example query to demonstrate its usage.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38705d3d",
        "outputId": "04fedc10-5222-4d43-cae3-ab1424cda362"
      },
      "source": [
        "def generate_response(retrieved_images):\n",
        "    \"\"\"\n",
        "    Generates a human-readable response string from a list of retrieved images.\n",
        "\n",
        "    Args:\n",
        "        retrieved_images (list): A list of dictionaries containing retrieved image information.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted string describing the retrieved images.\n",
        "    \"\"\"\n",
        "    if not retrieved_images:\n",
        "        return \"No relevant images were found.\"\n",
        "\n",
        "    response = \"Retrieved Images:\\n\"\n",
        "    for image_info in retrieved_images:\n",
        "        page_number = image_info.get('page_number', 'N/A')\n",
        "        image_index = image_info.get('image_index', 'N/A')\n",
        "        caption = image_info.get('caption', 'No caption available')\n",
        "        response += f\"- Image on Page {page_number}, Index {image_index}: {caption}\\n\"\n",
        "\n",
        "    return response\n",
        "\n",
        "# Example Usage:\n",
        "# Let's use a text query example from the previous step\n",
        "query = \"a red square\" # Example query based on dummy data\n",
        "retrieved_results = retrieve_images(query, captioned_images_list, index, index_to_image_info, embedding_model, N=3)\n",
        "\n",
        "# Generate and print the response\n",
        "response_string = generate_response(retrieved_results)\n",
        "print(response_string)\n",
        "\n",
        "# Example Usage:\n",
        "# Let's use a page number query example from the previous step\n",
        "query = \"0\" # Example query based on dummy data\n",
        "retrieved_results = retrieve_images(query, captioned_images_list, index, index_to_image_info, embedding_model, N=3)\n",
        "\n",
        "# Generate and print the response\n",
        "response_string = generate_response(retrieved_results)\n",
        "print(response_string)\n",
        "\n",
        "# Example Usage:\n",
        "# Let's use a number of images query example from the previous step\n",
        "query = \"first 1 images\" # Example query based on dummy data\n",
        "retrieved_results = retrieve_images(query, captioned_images_list, index, index_to_image_info, embedding_model, N=3)\n",
        "\n",
        "# Generate and print the response\n",
        "response_string = generate_response(retrieved_results)\n",
        "print(response_string)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query recognized as text question: \"a red square\"\n",
            "Retrieved 3 images based on text query.\n",
            "Retrieved Images:\n",
            "- Image on Page 12, Index 19: a yellow square with a white background\n",
            "- Image on Page 43, Index 0: a square with a blue background\n",
            "- Image on Page 12, Index 18: a brown square with a white border\n",
            "\n",
            "Query recognized as page number: 0\n",
            "Found 1 images on page 0.\n",
            "Retrieved Images:\n",
            "- Image on Page 0, Index 0: a white background with a blue and yellow text that reads reflect\n",
            "\n",
            "Query recognized as request for first 1 images.\n",
            "Retrieving the first 1 images.\n",
            "Retrieved Images:\n",
            "- Image on Page 0, Index 0: a white background with a blue and yellow text that reads reflect\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0dd5198"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The pipeline successfully extracted images from a PDF document using the `fitz` library.\n",
        "*   The \"Salesforce/blip-image-captioning-base\" model was successfully used to generate descriptive captions for the extracted images.\n",
        "*   A FAISS index was created to store the vector embeddings of the image captions, enabling efficient similarity search.\n",
        "*   A retrieval mechanism was implemented that can handle text-based queries (finding similar images based on captions), page number queries (finding images on a specific page), and requests for a specific number of images (retrieving the first N images).\n",
        "*   A response generation function was created to present the retrieved image information, including page number, index, and caption, in a human-readable format.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Integrate the pipeline components into a single, cohesive application or function that takes a PDF path and user query as input and returns the relevant image descriptions.\n",
        "*   Enhance the retrieval mechanism to handle more complex queries or combinations of query types, potentially incorporating re-ranking or other advanced retrieval techniques.\n"
      ]
    }
  ]
}